{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "def fetch_and_reshape_oecd_json(data_code,\n",
    "                                dimension_filter = 'all',\n",
    "                                time_and_other_filters = 'all?detail=Full'): \n",
    "    \"\"\"\n",
    "    the stats.oecd.org api [documentation](https://data.oecd.org/api/sdmx-json-documentation/)\n",
    "    outlines the taxonomy of a data request as:\n",
    "    \n",
    "    stats.oecd.org/sdmx-json/data/datasetcode/dimension_filter/time_and_other_filters\n",
    "    \n",
    "    E.g., say\n",
    "    * we want the \"Growth in GDP per capita, productivity and ULC\" data\n",
    "        + the data code is PDB_GR\n",
    "    * we want stats for Australia and USA\n",
    "        + their location codes are AUS, USA\n",
    "    * we're interested in \"GDP per capita, constant prices\", and \"GDP per hour worked, constant prices\"\n",
    "        + their measure codes are T_GDPPOP_V, T_GDPHRS_\n",
    "    * and we want to look at these measures through the perspectives of \n",
    "        + a valued indexed according to measure at 2010\n",
    "            - this has attribute code 2010Y\n",
    "        + Annual growth/change,\n",
    "            - this has attribute code GR\n",
    "        + Average growth rate\n",
    "            - this has attribute code AVGRW\n",
    "    * we want all data between 1970 and 2014\n",
    "        + we can use the filter \"all?startTime=1970&endTime=2014\"\n",
    "    * we want the full detail of the data:\n",
    "        + append \"&detail=Full\" to our time filter\n",
    "    \n",
    "    According to the API, we separate dimension and other filters by \"/\", and\n",
    "    inside the dimension filter we concatenate with \"+\" and separate with \".\".\n",
    "    Hence, our request would look like:\n",
    "        \n",
    "    http://stats.oecd.org/restsdmx/sdmx.ashx/GetData/PDB_GR/AUS+USA.T_GDPPOP_V+T_GDPHRS_V.2010Y+GRW+AVGRW/all?startTime=1970&endTime=2014&detail=Full\n",
    "    \n",
    "    If we just want to grab all data, and filter later (I highly suggest this):\n",
    "    \n",
    "    http://stats.oecd.org/restsdmx/sdmx.ashx/GetData/PDB_GR/all/all?detail=Full\n",
    "    \n",
    "    Unfortunately, the way the data is setup, your data comes back as in JSON format,\n",
    "    but the dataset spec is in XML and can be accessed via\n",
    "    \n",
    "    http://stats.oecd.org/restsdmx/sdmx.ashx/GetDataStructure/datasetcode\n",
    "    \n",
    "    For reshaping the data, the XML isn't necessary -- just fetch the data with \"detail=Full\"\n",
    "    in the request.\n",
    "    \n",
    "    Example input for a request for Income Disparity Data:\n",
    "    \n",
    "    idd_base_url = 'http://stats.oecd.org/sdmx-json/data/IDD'\n",
    "    dimension_filter = 'all' # grab all data\n",
    "    time_filter = 'all?startTime=2001&endTime=2014'\n",
    "    optional_filters = '&detail=Full' # pick up the measure unit's...\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"parse json data into DataFrame:\n",
    "\n",
    "    the json comes with a 'structure' section which explains how to\n",
    "    interpret the keys (e.g. 1:2:3:4:5) for the observations.\n",
    "\n",
    "    We first need to parse the 'structure' to figure out what the\n",
    "    dimension names (and order) is. Then, we need to unpack\n",
    "    observation values into floats (as opposed to arrays)\n",
    "    \"\"\"\n",
    "    idd_base_url = \"http://stats.oecd.org/restsdmx/sdmx.ashx/GetData/\" \n",
    "    data_query = idd_base_url + '/' + data_code + '/' + dimension_filter + '/' + time_and_other_filters\n",
    "    stats_oecd_idd = json.loads(urllib.request.urlopen(data_query).read().decode('utf-8'))\n",
    "\n",
    "    metadata_stats_oecd_idd = stats_oecd_idd['structure']['dimensions']\n",
    "    print(stats_oecd_idd['structure'].keys())\n",
    "\n",
    "    col_names = []\n",
    "    for dim in metadata_stats_oecd_idd['series']:\n",
    "        col_names.append(dim['id'].lower())\n",
    "\n",
    "    idd_dataframe = pd.DataFrame()\n",
    "\n",
    "    \"\"\"\n",
    "    The observation attributes come in a particularly ordered array, e.g.: [1, 20, 3, None]...\n",
    "    0  => attributes_stats_oecd_idd['series'][0][1],\n",
    "    20 => attributes_stats_oecd_idd['series'][1][20],\n",
    "    3 => attributes_stats_oecd_idd['series'][2][3],\n",
    "    None => !!! this shouldn't be mapped.\n",
    "    \"\"\"\n",
    "    \n",
    "    observation_attribute_map = stats_oecd_idd['structure']['attributes']['series']\n",
    "    attribute_column_names = [attribute_map['id'].lower() for attribute_map in observation_attribute_map]\n",
    "    #= [(x + \"_id\").lower() for x in attribute_ids]\n",
    "    #print(attribute_ids)\n",
    "\n",
    "    for key, value in stats_oecd_idd['dataSets'][0]['series'].items():\n",
    "        \"\"\"\n",
    "        Example (key, value):\n",
    "        ('19:8:0:0:0',\n",
    "        {'attributes': [0, 20, 0, None],\n",
    "         'observations': {'0': [43696.0, None], '6': [45934.0, None]}})\n",
    "        So, extract info from key, and value.attributes\n",
    "        \"\"\"      \n",
    "        data = pd.DataFrame(dict(zip(col_names, [[x] for x in key.split(\":\")])))\n",
    "        data_attributes = [str(x) for x in value['attributes']] # metadata should be in string form, since it's categorical\n",
    "        data = pd.concat([data,\n",
    "                          pd.DataFrame(dict(zip(attribute_column_names, data_attributes)), index=[0])],\n",
    "                         axis = 1)    \n",
    "\n",
    "        observations = copy.copy(value['observations'])\n",
    "\n",
    "        for time, measure in observations.items():\n",
    "            observations[time] = measure[0]\n",
    "\n",
    "        observations = pd.DataFrame(list(observations.items()), columns=['time_period','observation'])\n",
    "\n",
    "        observations['location'] = data['location'].iloc[0]\n",
    "\n",
    "        data = pd.merge(right=data,\n",
    "                        left=observations,\n",
    "                        on='location',\n",
    "                        how='outer')\n",
    "\n",
    "        idd_dataframe = idd_dataframe.append(data, ignore_index=False)\n",
    "    return idd_dataframe, metadata_stats_oecd_idd, observation_attribute_map\n",
    "\n",
    "def append_metadata_to_oecd_stats(idd_dataframe, metadata_stats_oecd_idd, observation_attribute_map):\n",
    "    \"\"\"\n",
    "    Append meta data to OECD stats dataframe:\n",
    "\n",
    "    the returned JSON has a 'structure' object with 'dimensions'\n",
    "    child that contains all the information to translate series\n",
    "    identifiers x:y:z:w:a into something human parsable.\n",
    "\n",
    "    A series of merges should be anticipated. Hence, it makes\n",
    "    sense to store all the metadata in a dictionary where the\n",
    "    keys will be the merge indices.\n",
    "    \"\"\"\n",
    "    oecd_metadata = {}\n",
    "    for metadata in [metadata_stats_oecd_idd['series'], observation_attribute_map]:\n",
    "        for dim in metadata:            \n",
    "            dim_dataframe = pd.DataFrame(dim['values'])\n",
    "            dim_id = dim['id'].lower()\n",
    "\n",
    "            # if dim_dataframe is empty, we cannot rename the columns\n",
    "            try:\n",
    "                dim_dataframe.columns = [dim_id + '_code', dim_id + '_name']\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "            dim_dataframe[dim_id] = dim_dataframe.index.astype(str)\n",
    "            oecd_metadata[dim_id] = dim_dataframe\n",
    "\n",
    "    # make time metadata\n",
    "    time_metadata = metadata_stats_oecd_idd['observation'][0]\n",
    "    time_metadata_index = time_metadata['role'].lower()\n",
    "    time_metadata_df = pd.DataFrame(time_metadata['values'])\n",
    "    time_metadata_df.columns = ['year', time_metadata_index]\n",
    "    time_metadata_df[time_metadata_index] = time_metadata_df.index.astype(str)\n",
    "\n",
    "    oecd_metadata[time_metadata_index] = time_metadata_df\n",
    "\n",
    "    for key, df in oecd_metadata.items():\n",
    "        # no point merging on empty data\n",
    "        if df.empty:\n",
    "            continue\n",
    "        idd_dataframe = pd.merge(left=idd_dataframe,\n",
    "                                 right=df,\n",
    "                                 how='left',\n",
    "                                 on=key)\n",
    "    return idd_dataframe\n",
    "\n",
    "def fetch_and_format_oecd_data(idd_base_url = 'http://stats.oecd.org/sdmx-json/data/IDD',\n",
    "                               dimension_filter = 'all', # grab all data\n",
    "                               time_filter = 'all?startTime=2001&endTime=2014',\n",
    "                               optional_filters = '&detail=Full'):\n",
    "    return append_metadata_to_oecd_stats(*fetch_oecd_data(idd_base_url, dimension_filter, time_filter, optional_filters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = fetch_and_format_oecd_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['description', 'annotations', 'dimensions', 'name', 'attributes', 'links'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['time_period', 'observation', 'location', 'age', 'definition',\n",
       "       'measure', 'methodo', 'powercode', 'referenceperiod', 'time_format',\n",
       "       'unit', 'time_format_code', 'time_format_name', 'year', 'location_code',\n",
       "       'location_name', 'unit_code', 'unit_name', 'powercode_code',\n",
       "       'powercode_name', 'definition_code', 'definition_name', 'age_code',\n",
       "       'age_name', 'measure_code', 'measure_name', 'methodo_code',\n",
       "       'methodo_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.to_csv(\"~/repos/middle_middle/oecd_idd.csv\",index=False,header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
